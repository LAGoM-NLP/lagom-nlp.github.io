@string{acl = {Association for Computational Linguistics,}}

@inproceedings{bauwens-delobelle-2024-bpe,
  title       = {{BPE}-knockout: Pruning Pre-existing {BPE} Tokenisers with Backwards-compatible Morphological Semi-supervision},
  author      = {Bauwens, Thomas  and Delobelle, Pieter},
  booktitle   = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  month       = jun,
  year        = {2024},
  address     = {Mexico City, Mexico},
  publisher   = {Association for Computational Linguistics},
  url         = {https://aclanthology.org/2024.naacl-long.324},
  pages       = {5810--5832},
  abstract    = {Byte-pair encoding (BPE) has become the default subword tokeniser in language models (LMs), allowing the representation of an infinite space of text with a finite set of units. Yet, BPE training is unsupervised, receiving no explicit information about a language{'}s morphology. This results in a subword vocabulary wherein many units are a concatenation of partial morphemes, preventing their formation as tokens. This, in turn, causes consistent intra-word patterns to be displayed inconsistently to downstream models, and bloats the vocabulary, hence requiring unnecessary embedding storage. In this paper, we address this issue by identifying blameworthy BPE merges and removing the resulting subwords from the BPE vocabulary, without impeding further use of merges that relied on them. We find that our method, BPE-knockout, is effective at making BPE{'}s segmentation positions adhere better to derivational and compound boundaries in English, Dutch and German, and improves token-based tasks in Dutch RoBERTa models, indicating that a tokeniser{'}s adherence to morphology impacts downstream models. We demonstrate the latter not only by training LMs from scratch, but also by continuing the pre-training of existing LMs. This proves promising, showing that suboptimal tokenisers can be remedied whilst salvaging training cost of downstream LMs.},
  abbr        = {NAACL},
  bibtex_show = true,
  slides      = {https://s3.amazonaws.com/pf-user-files-01/u-59356/uploads/2024-05-19/yl43q5v/Beamer_notimestamps.pdf},
  video       = {https://s3.amazonaws.com/pf-user-files-01/u-59356/uploads/2024-05-19/9123qlr/NAACL2024_BPE-knockout.mp4},
  poster      = {https://lagom-nlp.github.io/cdn/posters/pdf/2024/thomas/poster_bauwens2024_bpe-knockout.pdf}
}


@inproceedings{ploeger2024what,
  title       = {What Is {{``Typological Diversity''}} in {{NLP}}?},
  author      = {Ploeger*, Esther and Poelman*, Wessel and {de Lhoneux}, Miryam and Bjerva, Johannes},
  booktitle   = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  year        = {2024},
  month       = nov,
  publisher   = {Association for Computational Linguistics},
  url         = {http://arxiv.org/abs/2402.04222},
  abstract    = {The NLP research community has devoted increased attention to languages beyond English, resulting in considerable improvements for multilingual NLP. However, these improvements only apply to a small subset of the world's languages. Aiming to extend this, an increasing number of papers aspires to enhance generalizable multilingual performance across languages. To this end, linguistic typology is commonly used to motivate language selection, on the basis that a broad typological sample ought to imply generalization across a broad range of languages. These selections are often described as being 'typologically diverse'. In this work, we systematically investigate NLP research that includes claims regarding 'typological diversity'. We find there are no set definitions or criteria for such claims. We introduce metrics to approximate the diversity of language selection along several axes and find that the results vary considerably across papers. Furthermore, we show that skewed language selection can lead to overestimated multilingual performance. We recommend future work to include an operationalization of 'typological diversity' that empirically justifies the diversity of language samples.},
  abbr        = {EMNLP},
  bibtex_show = true
}

@inproceedings{tatariya2024pixology,
  title = {Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models},
  author = {Tatariya, Kushal and Araujo, Vladimir and Bauwens, Thomas and {de Lhoneux}, Miryam},
  year = {2024},
  publisher   = {Association for Computational Linguistics},
  booktitle   = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  url = {https://arxiv.org/abs/2410.12011},
  abbr        = {EMNLP},
  bibtex_show = true
}

@inproceedings{remy-delobelle2024transtokenization,
  title = {Trans-Tokenization and Cross-lingual Vocabulary Transfers: Language Adaptation of {LLM}s for Low-Resource {NLP}},
  author = {Remy, Fran{\c{c}}ois and Delobelle, Pieter and Avetisyan, Hayastan and Khabibullina, Alfiya and {de Lhoneux}, Miryam and Demeester, Thomas},
  booktitle = {First Conference on Language Modeling},
  year = {2024},
  url = {https://openreview.net/forum?id=sBxvoDhvao},
  abbr = {COLM},
  bibtex_show = true
}

@inproceedings{poelman2024roles,
  title = {The {{Roles}} of {{English}} in {{Evaluating Multilingual Language Models}}},
  author = {Poelman, Wessel and {de Lhoneux}, Miryam},
  booktitle = {The {{Joint}} 25th {{Nordic Conference}} on {{Computational Linguistics}} and 11th {{Baltic Conference}} on {{Human Language Technologies}}},
  year = {2025},
  month = mar,
  url = {http://arxiv.org/abs/2412.08392},
  abstract = {Multilingual natural language processing is getting increased attention, with numerous models, benchmarks, and methods being released for many languages. English is often used in multilingual evaluation to prompt language models (LMs), mainly to overcome the lack of instruction tuning data in other languages. In this position paper, we lay out two roles of English in multilingual LM evaluations: as an interface and as a natural language. We argue that these roles have different goals: task performance versus language understanding. This discrepancy is highlighted with examples from datasets and evaluation setups. Numerous works explicitly use English as an interface to boost task performance. We recommend to move away from this imprecise method and instead focus on furthering language understanding.},
  abbr = {NoDaLiDa},
  bibtex_show = true
}

@inproceedings{bauwens-etal-2025-grampa,
    title = "{GR}a{MP}a: Subword Regularisation by Skewing Uniform Segmentation Distributions with an Efficient Path-counting {M}arkov Model",
    author = "Bauwens, Thomas  and
      Kacz{\'e}r, David  and
      De Lhoneux, Miryam",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.acl-long.1180/",
    pages = "24228--24257",
    ISBN = "979-8-89176-251-0",
    abbr = {ACL},
    abstract = "Stochastically sampling word segmentations from a subword tokeniser, also called subword regularisation, is a known way to increase robustness of language models to out-of-distribution inputs, such as text containing spelling errors. Recent work has observed that usual augmentations that make popular deterministic subword tokenisers stochastic still cause only a handful of all possible segmentations to be sampled. It has been proposed to uniformly sample across these instead, through rejection sampling of paths in an unweighted segmentation graph. In this paper, we argue that uniformly random segmentation in turn skews the distributions of certain segmentational properties (e.g. token lengths and amount of tokens produced) away from uniformity, which still ends up hiding meaningfully diverse tokenisations. We propose an alternative uniform sampler using the same segmentation graph, but weighted by counting the paths through it. Our sampling algorithm, GRaMPa, provides hyperparameters allowing sampled tokenisations to skew towards fewer, longer tokens. Furthermore, GRaMPa is single-pass, guaranteeing significantly better computational complexity than previous approaches relying on rejection sampling. We show experimentally that language models trained with GRaMPa outperform existing regularising tokenisers in a data-scarce setting on token-level tasks such as dependency parsing, especially with spelling errors present.",
    bibtex_show = true
}

@inproceedings{vandermeerschen-de-lhoneux-2025-supervised,
    title = "Supervised and Unsupervised Probing of Shortcut Learning: Case Study on the Emergence and Evolution of Syntactic Heuristics in {BERT}",
    author = "Vandermeerschen, Elke  and
      De Lhoneux, Miryam",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2025",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-acl.499/",
    pages = "9592--9604",
    ISBN = "979-8-89176-256-5",
    abbr = {ACL (Findings)},
    abstract = "Contemporary language models (LMs) such as BERT (Devlin et al., 2019, T5 (Raffel et al., 2023), GPT-4 (OpenAI, 2023), have exhibited remarkable capabilities, effectively addressing long-standing challenges in the field. However, these models rely on shortcut learning, using a decision rule that relies on superficial cues that are spuriously correlated with the labels (Geirhos et al., 2020). In this research, we focus on the reliance on a specific type of shortcuts, namely syntactic heuristics, in BERT when performing Natural Language Inference (NLI), a representative task in Natural Language Understanding (Jeretic et al., 2020). By making use of two probing methods, one supervised, one unsupervised, we investigate where these shortcuts emerge, how they evolve and how they impact the latent knowledge of the LM. Our findings reveal that syntactic heuristics are absent in pretrained models but emerge and evolve as the model is finetuned with datasets of increasing size. The adoption of these shortcuts varies across different hidden layers, with specific layers closer to the output contributing more to this phenomenon. Despite the model{'}s reliance on shortcuts during inference, it retains information relevant to the task, and our supervised and unsupervised probes process this information differently.",
    bibtex_show = true
}