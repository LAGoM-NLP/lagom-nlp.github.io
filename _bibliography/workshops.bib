@inproceedings{tatariya_transfer_2023,
	address = {Toronto, Canada},
	title = {Transfer {Learning} for {Code}-{Mixed} {Data}: {Do} {Pretraining} {Languages} {Matter}?},
	shorttitle = {Transfer {Learning} for {Code}-{Mixed} {Data}},
	url = {https://aclanthology.org/2023.wassa-1.32},
	doi = {10.18653/v1/2023.wassa-1.32},
	abstract = {Monolinguals make up a minority of the world's speakers, and yet most language technologies lag behind in handling linguistic behaviours produced by bilingual and multilingual speakers. A commonly observed phenomenon in such communities is code-mixing, which is prevalent on social media, and thus requires attention in NLP research. In this work, we look into the ability of pretrained language models to handle code-mixed data, with a focus on the impact of languages present in pretraining on the downstream performance of the model as measured on the task of sentiment analysis. Ultimately, we find that the pretraining language has little effect on performance when the model sees code-mixed data during downstream finetuning. We also evaluate the models on code-mixed data in a zero-shot setting, after task-specific finetuning on a monolingual dataset. We find that this brings out differences in model performance that can be attributed to the pretraining languages. We present a thorough analysis of these findings that also looks at model performance based on the composition of participating languages in the code-mixed datasets.},
	urldate = {2023-12-27},
	booktitle = {Proceedings of the 13th {Workshop} on {Computational} {Approaches} to {Subjectivity}, {Sentiment}, \& {Social} {Media} {Analysis}},
	publisher = {Association for Computational Linguistics},
	author = {Tatariya, Kushal and Lent, Heather and de Lhoneux, Miryam},
	editor = {Barnes, Jeremy and De Clercq, Orphée and Klinger, Roman},
	month = jul,
	year = {2023},
	pages = {365--378},

    abbr = {WASSA},
    bibtex_show = true,
	poster = {https://lagom-nlp.github.io/cdn/posters/pdf/2024/kushal/poster-codemix.pdf},
}


@inproceedings{tatariya_sociolinguistically_2024,
	address = {St. Julian's, Malta},
	title = {Sociolinguistically {Informed} {Interpretability}: {A} {Case} {Study} on {Hinglish} {Emotion} {Classification}},
	shorttitle = {Sociolinguistically {Informed} {Interpretability}},
	url = {https://aclanthology.org/2024.sigtyp-1.9},
	abstract = {Emotion classification is a challenging task in NLP due to the inherent idiosyncratic and subjective nature of linguistic expression,especially with code-mixed data. Pre-trained language models (PLMs) have achieved high performance for many tasks and languages, but it remains to be seen whether these models learn and are robust to the differences in emotional expression across languages. Sociolinguistic studies have shown that Hinglish speakers switch to Hindi when expressing negative emotions and to English when expressing positive emotions. To understand if language models can learn these associations, we study the effect of language on emotion prediction across 3 PLMs on a Hinglish emotion classification dataset. Using LIME and token level language ID, we find that models do learn these associations between language choice and emotional expression. Moreover, having code-mixed data present in the pre-training can augment that learning when task-specific data is scarce. We also conclude from the misclassifications that the models may overgeneralise this heuristic to other infrequent examples where this sociolinguistic phenomenon does not apply.},
	urldate = {2024-03-22},
	booktitle = {Proceedings of the 6th {Workshop} on {Research} in {Computational} {Linguistic} {Typology} and {Multilingual} {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Tatariya, Kushal and Lent, Heather and Bjerva, Johannes and De Lhoneux, Miryam},
	editor = {Hahn, Michael and Sorokin, Alexey and Kumar, Ritesh and Shcherbakov, Andreas and Otmakhova, Yulia and Yang, Jinrui and Serikov, Oleg and Rani, Priya and Ponti, Edoardo M. and Muradoğlu, Saliha and Gao, Rena and Cotterell, Ryan and Vylomova, Ekaterina},
	month = mar,
	year = {2024},
	pages = {66--74},
	file = {Full Text PDF:/home/kushal/Zotero/storage/YAIHDJYF/Tatariya et al. - 2024 - Sociolinguistically Informed Interpretability A C.pdf:application/pdf},

    abbr = {SIGTYP},
    bibtex_show = true,
	poster = {https://lagom-nlp.github.io/cdn/posters/pdf/2024/kushal/poster-LIME.pdf},
}

@inproceedings{poelman2024call,
  title = {A {{Call}} for {{Consistency}} in {{Reporting Typological Diversity}}},
  booktitle = {Proceedings of the 6th {{Workshop}} on {{Research}} in {{Computational Linguistic Typology}} and {{Multilingual NLP}}},
  author = {Poelman, Wessel and Ploeger, Esther and {de Lhoneux}, Miryam and Bjerva, Johannes},
  editor = {Hahn, Michael and Sorokin, Alexey and Kumar, Ritesh and Shcherbakov, Andreas and Otmakhova, Yulia and Yang, Jinrui and Serikov, Oleg and Rani, Priya and Ponti, Edoardo M. and Murado{\u g}lu, Saliha and Gao, Rena and Cotterell, Ryan and Vylomova, Ekaterina},
  year = {2024},
  month = mar,
  pages = {75--77},
  publisher = {Association for Computational Linguistics},
  address = {St. Julian's, Malta},
  url = {https://aclanthology.org/2024.sigtyp-1.10},
  urldate = {2024-04-22},
  abstract = {In order to draw generalizable conclusions about the performance of multilingual models across languages, it is important to evaluate on a set of languages that captures linguistic diversity.Linguistic typology is increasingly used to justify language selection, inspired by language sampling in linguistics.However, justifications for `typological diversity' exhibit great variation, as there seems to be no set definition, methodology or consistent link to linguistic typology.In this work, we provide a systematic insight into how previous work in the ACL Anthology uses the term `typological diversity'.Our two main findings are: 1) what is meant by typologically diverse language selection is not consistent and 2) the actual typological diversity of the language sets in these papers varies greatly.We argue that, when making claims about `typological diversity', an operationalization of this should be included.A systematic approach that quantifies this claim, also with respect to the number of languages used, would be even better.},

  abbr = {SIGTYP},
  bibtex_show = true
}
