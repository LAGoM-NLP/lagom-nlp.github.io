@misc{lent_creoleval_2023,
	title = {{CreoleVal}: {Multilingual} {Multitask} {Benchmarks} for {Creoles}},
	shorttitle = {{CreoleVal}},
	url = {http://arxiv.org/abs/2310.19567},
	doi = {10.48550/arXiv.2310.19567},
	abstract = {Creoles represent an under-explored and marginalized group of languages, with few available resources for NLP research. While the genealogical ties between Creoles and other highly-resourced languages imply a significant potential for transfer learning, this potential is hampered due to this lack of annotated data. In this work we present CreoleVal, a collection of benchmark datasets spanning 8 different NLP tasks, covering up to 28 Creole languages; it is an aggregate of brand new development datasets for machine comprehension, relation classification, and machine translation for Creoles, in addition to a practical gateway to a handful of preexisting benchmarks. For each benchmark, we conduct baseline experiments in a zero-shot setting in order to further ascertain the capabilities and limitations of transfer learning for Creoles. Ultimately, the goal of CreoleVal is to empower research on Creoles in NLP and computational linguistics. We hope this resource will contribute to technological inclusion for Creole language users around the globe.},
	urldate = {2023-12-27},
	publisher = {arXiv},
	author = {Lent, Heather and Tatariya, Kushal and Dabre, Raj and Chen, Yiyi and Fekete, Marcell and Ploeger, Esther and Zhou, Li and Heje, Hans Erik and Kanojia, Diptesh and Belony, Paul and Bollmann, Marcel and Grobol, Loïc and de Lhoneux, Miryam and Hershcovich, Daniel and DeGraff, Michel and Søgaard, Anders and Bjerva, Johannes},
	month = oct,
	year = {2023},
	note = {arXiv:2310.19567 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},

    abbr = {arXiv},
    bibtex_show = true
}

@misc{tatariya_sociolinguistically_2024,
	title = {Sociolinguistically {Informed} {Interpretability}: {A} {Case} {Study} on {Hinglish} {Emotion} {Classification}},
	shorttitle = {Sociolinguistically {Informed} {Interpretability}},
	url = {http://arxiv.org/abs/2402.03137},
	abstract = {Emotion classification is a challenging task in NLP due to the inherent idiosyncratic and subjective nature of linguistic expression, especially with code-mixed data. Pre-trained language models (PLMs) have achieved high performance for many tasks and languages, but it remains to be seen whether these models learn and are robust to the differences in emotional expression across languages. Sociolinguistic studies have shown that Hinglish speakers switch to Hindi when expressing negative emotions and to English when expressing positive emotions. To understand if language models can learn these associations, we study the effect of language on emotion prediction across 3 PLMs on a Hinglish emotion classification dataset. Using LIME and token level language ID, we find that models do learn these associations between language choice and emotional expression. Moreover, having code-mixed data present in the pre-training can augment that learning when task-specific data is scarce. We also conclude from the misclassifications that the models may overgeneralise this heuristic to other infrequent examples where this sociolinguistic phenomenon does not apply.},
	urldate = {2024-02-06},
	publisher = {arXiv},
	poster = {https://lagom-nlp.github.io/posters/pdf/2024/kushal/poster-LIME.pdf},
	author = {Tatariya, Kushal and Lent, Heather and Bjerva, Johannes and de Lhoneux, Miryam},
	month = feb,
	year = {2024},
	note = {arXiv:2402.03137 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},

    abbr = {arXiv},
    bibtex_show = true
}
